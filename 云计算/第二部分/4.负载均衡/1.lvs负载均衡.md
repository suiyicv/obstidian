
# 一.集群技术概述
## 1.集群技术类型
负载均衡集群， Load Balance LB  
高可用集群，     High Avalibility HA
## 2.负载均衡技术
服务器单台机器的性能毕竟是有限的，假设单台机器所能承载的客户端连接最多只有一万当单个客户端的访问量超过一万的时候，<span style="background:#affad1">超过了这个单机的处理瓶颈</span>，就会造成客户端访问越来越慢

如何解决这个问题？
1.scale in  <span style="background:#affad1">向内扩展</span>：去升级这个机器的配置，缺点：成本太高。适用于个人pc的扩展
2.scale out <span style="background:#affad1">向外扩展</span>：负载均衡集群的思想，通过增加机器的数量
涉及到一个话题，摆了三个一摸一样的机器，这三个机器肯定是三个不同的ip地址

后端找多个服务器，来跑一摸一样的业务
第一：为了方便客户端的访问
第二：让着三个服务器能够共同承担所有的流量
后端前面会放一个负载均衡器，由负载均衡器来接受客户端的请求，然后这个负载均衡器，通过一定的策略或者说算法，再有这个负载均衡器把客户端的请求分别转发到相应的业务服务器，由业务服务器来处理真正的请求

<span style="background:#affad1">一个负载均衡集群</span>
![[Pasted image 20240610224539.png]]

**负载均衡器**
负载均衡器，要是真正实现负载均衡的功能，流量分发的功能，这个东西他带具备什么样子的能力
1.接受请求的能力，创建虚拟服务
2.添加后端的服务器
**实现方式**
1.软件 nginx(upstream),lvs,haproxy
2.硬件 F5
最终目的：提升业务的并发
## 3.高可用技术
<span style="background:#affad1">避免关键业务的单点故障</span>  
通过优先级选择主备角色，主负责转发[客户端](https://so.csdn.net/so/search?q=%E5%AE%A2%E6%88%B7%E7%AB%AF&spm=1001.2101.3001.7020)流量 ，同时会向备发送心跳信息，备一段时间内接收不到心跳，会认为主宕机故障，自动会接替主的工作继续转发流量
![[Pasted image 20240610234149.png]]
如果这个负载均衡器故障了，那整个业务就坏了，为了避免负载均衡器成为单点故障，我们可以再额外加一个负载均衡器。主要目的就是为了让他们<span style="background:#affad1">形成一个高可用</span>或者说，是让这俩负载均衡器形成一个<span style="background:#affad1">备份</span>
<span style="background:#affad1">同一时间只有一个负载均衡器在工作</span>
假设客户端正常访问我们的业务的时候，所有的流量都走上面的负载均衡器，一旦检测到上面的负载均衡器故障了以后，会自动的切换到下面的负载均衡器，这样子客户端就可以继续访问我们的业务。
两个负载均衡器，肯定有所谓的<span style="background:#affad1">主备</span>。
假设上面的是主，那下面的自然是备

**两个问题：**
1.两负载均衡器摆在这里，靠什么决定谁当主，谁当备的呢？
靠我们人为的给这两个负载均衡器，配置一个优先级，优先级：1-255之间的数字
谁的数字越大，谁的优先级就越高
高可用一旦主备角色确认好之后上面的主调度，除了会转发正常的客户端流量之外
这个主调度还会负责另一件事情，就是周期性的向这个备调度，发从<span style="background:#affad1">心跳</span>信息
默认一秒发一次
只要备调度，能够正常接收到这个心跳，那他就知道这个主调度是正常运行的
连续一段时间（<span style="background:#affad1">三秒</span>）接受不到主调度发送的心跳信息，则认为主调度故障
，然后备调度就会接替主调度的工作，继续向机器内部转发流量。

# 二.负载均衡 LVS

## 1.LVS介绍
linux virtual service Linux虚拟服务
集成在内核中负载均衡模块  
国内<span style="background:#affad1">章文嵩博士</span>研发，只要你用的是Linux内核里面都会有lvs
## 2.负载均衡策略/算法
<span style="background:#affad1">rr    </span>    轮询，解决会话持久的问题  
<span style="background:#affad1">wrr </span> 加权轮询，为后端服务器设置不同的权重值  
<span style="background:#affad1">lc    </span>    最少连接  
<span style="background:#affad1">wlc </span> 加权最少连接 【默认】  
<span style="background:#affad1">sh   </span>   源hash，一段时间内, 同一个客户端的访问请求会转发到同一个后端服务器
## 3.LVS设计模式
 **nat模式**
 请求、响应都是要经过调度器
 **dr模式**
 直接路由模式，请求经过调度器，响应由后端服务器直接响应给客户端
 **tun隧道模式（根本不用）**

![[Pasted image 20240611073539.png]]
**nat模式**箭头都是双向的，代表，如果你要用nat模式，客户端的访问请求肯定是要经过调度器来进入集群，什么叫双向？将来后端的服务器给客户端的响应也是要经过调度器出去。所以，将来我们以nat的模式设计负载均衡集群的时候，不建议后端业务的服务器数量太多，10个以内，太多可能会造成调度器的阻塞，影响业务访问的速度
![[Pasted image 20240611073949.png|379]]
**dr模式**客户端的请求肯定都是要经过调度器来进入后端服务器，但是后端的服务器发送响应直接给客户端。后端上的服务器，要是想直接能给互联网上的客户端响应，这意味着你后端服务器必须都得能<span style="background:#affad1">正常联网</span>。
### 3.1 nat模式的注意事项
![[Pasted image 20240611074427.png]]
后端真实务器的ip叫<span style="background:#affad1">RIP</span>。负载调度均衡器上面需要两个ip 一个叫<span style="background:#affad1">vip</span>，一个叫<span style="background:#affad1">dip</span>
dip：就是用来让这个负载均衡器向后端转发请求的时候，用这个dip和后端的服务器重新通信
vip：虚拟ip
```ad-note
注意：负载均衡的vip和dip要分属两个不同的网络，所以负载均衡器上面就要开启路由转发的功能，后端所有服务器的网关得是dip
```
VIP、DIP要属于两个不同的网络  
负载均衡器要开启路由转发功能  
所有real server的网关要指向DIP
### 3.2 nat模式配置
两台web服务器
192.168.137.200 eth0 网关：192.168.137.199
192.168.137.201 eth0 网关：192.168.137.199
一台调度器
vip:192.168.136.100 eth0
dip:192.168.137.199 eth1
```bash
192.168.137.200 ping 192.168.137.199
```
![[Pasted image 20240611090841.png]]
```bash
192.168.137.201 ping 192.168.137.199
```
![[Pasted image 20240611090943.png]]
#### (1)调度器安装ipvsadm软件
```bash
yum install -y ipvsadm
```
#### (2)开启路由转发
```bash
sysctl  -a | grep ip_forward
```
![[Pasted image 20240611091939.png]]
此时路由转发未开启
```bash
vim  /etc/sysctl.conf
net.ipv4.ip_forward = 1
sysctl -p                           # 让其生效
```
![[Pasted image 20240611092316.png]]

#### (3)创建虚拟服务
```bash
ipvsadm -A -t 192.168.136.100:80 -s  rr    # -s 添加调算法
```
#### (4)添加后端real server
```bash
ipvsadm -a -t 192.168.136.100:80 -r 192.168.137.200:80 -m
ipvsadm -a -t 192.168.136.100:80 -r 192.168.137.201:80 -m
```
#### (5)查看虚拟服务
```bash
ipvsadm -L -n
```
![[Pasted image 20240611092917.png]]
#### (6)测试访问
![[Pasted image 20240611093042.png]]
### 3.3 dr模式的注意事项
直接路由模式
所有的real server必须要配置VIP，目的是为了可以正常接收请求  
所有的real server修改两个参数  
<span style="background:#affad1">arp_ignore=1</span>        避免VIP产生冲突  
<span style="background:#affad1">arp_announce=2</span>  避免客户端直接访问后端的real server，失去负载均衡的效果

将来用lvs的dr模式来设计集群的话，你最起码要确保你后端所有real server的网关。得是世界网络里面真是的网关，就是确保你的后端server能和客户端所在的网络正常通信，这样子才能把响应直接返回给客户端。
![[Pasted image 20240611093748.png]]不需要区分网络
web服务器
192.168.137.200 /192.168.137.100/32
192.168.137.201 /192.168.137.100/32
调度器
vip:192.168.137.100/32
dip:192.168.137.199
不需要添加额外的网卡，通过使用虚拟网卡
### 3.4 dr模式的配置
#### (1)所有real serve 添加vip
给lo网卡添加一个ip,并且vip的掩码,必须是32为掩码
```bash
ip addr add dev lo 192.168.137.100/32
```
32位掩码代码没有主机位，网络中只有这一个IP
#### (2)所有real server修改arp系统参数
```bash
vim /etc/sysctl.conf
net.ipv4.conf.all.arp_ignore = 1 
net.ipv4.conf.all.arp_announce = 2
sysctl -p  # 使其生效
```
#### (3)创建虚拟服务
```bash
ip addr add dev lo 192.168.137.100/32
ip addr show
ipvsadm -A -t 192.168.137.100:80 -s rr
```
(4)添加后端的real server
```bash
ipvsadm -a -t 192.168.137.100:80 -r 192.168.137.200:80 -g
ipvsadm -a -t 192.168.137.100:80 -r 192.168.137.201:80 -g
ipvsadm -L -n
```
![[Pasted image 20240611102906.png]]
#### (5)测试访问
![[Pasted image 20240611103030.png]]
# 三.持久性连接
一段时间内，同一个客户端请求会转发到同一个后端服务器 ,<span style="background:#affad1">解决会话持久问题</span>
```bash
ipvsadm -E -t 192.168.140.100:80 -s rr -p 300
ipvsadm -L -n
```
![[Pasted image 20240611103728.png]]
测试
![[Pasted image 20240611103803.png]]
