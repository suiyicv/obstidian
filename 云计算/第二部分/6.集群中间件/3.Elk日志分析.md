# 一.elk作用
做日志分析
<span style="background:#affad1">做统一的日志搜集，分析</span>
Linux做运维，除了一些平台的部署维护，我们还要再日志的统计分析搜集，也是个很重要的日常工作

elk方便我们做啥呢？
和我们之前讲的lb负载均衡集群有关,负载均衡集群--Load Balance LB  
![[Pasted image 20240622142634.png]]
前端有一些负载均衡器，后端有一些我们的业务
客户端访问这个负载均衡器，负载均衡器会把客户端的请求，分散，或者说随机发布到后端的业务服务器上
我们现在从日志的角度来讲
网站都有所谓的访问日志，你要是说这个业务是集群的结构的话，客户端有的请求会到第一个业务服务器，有的回到第三个业务服务器上
不同的客户端请求，可能会随机到不同的业务服务器上

如果你的客户端的请求到了第一个机器上面，那这一次客户端相关的访问，产生的日志信息都在第一个机器上记录，下一波请求，到第三个业务服务器上了，那这些日志都会记录到第三个机器上

核心一点：后端的业务服务器不管有多少个，他最终跑的都是统一套网站A，后续要对这个网站的访问日志做统一的分析，比如我们要分析这个也页面的访问量，这个怎么处理呢？
以前小规模的环境，可能项目结构非常简单，就一个单一服务器上面，只需要对一个机器上的日志进行分析就行了
但是在我们集群环境里，日志是分散在不同的机器上面的，那在做访问量分析的收，首先要做的一件事就是要把这些机器上面的所有日志给搜集过来。

基于这一种需求，然后就有了相关的工具，比如elk
就是在你的项目结构上面在搞一套elk机器
![[Pasted image 20240622144454.png]]
根据我们的配置把业务服务器上面我们需要的日志统一全都集中到elk身上来，然后方便在elk上做一些统一的分析，统一的处理。

但是要是放在公司实际干活的时候，就比如说我们日常出一点错，你带去找错误日志去，这样子也可以借助elk查看这些错误日志

# 二.核心组件
elk部署好了之后，elk至少是一个单独的机器，他凭什么能去我们这些业务服务器上面搜集数据去？
要想连接业务服务器，业务服务器上面，必须要求<span style="background:#affad1">相应的客户端</span>，所以我们需要在业务服务器上面部署客户端软件，这些软件我们统称为<span style="background:#affad1">beat</span>
部署在业务服务器的客户端agent，用于让elk联系beat采用日志
代表性的beat

<span style="background:#affad1">topbeat</span>：适合搜集系统级别的日志效率比较高
![[Pasted image 20240622145358.png]]
<span style="background:#affad1">filebeat</span>:   适用于搜集应用级别的日志
<span style="background:#affad1">winbeat</span>:  适用于windows日志
packetbeat：适用于网络设备的日志

这些beat软件都是go语言开发的，可以学学go语言

ELK
## 1.elasticsearch <span style="background:#affad1">ES</span>
高性能分布式搜索引擎，提供数据存储和数据搜索的功能
这个软件可以单独用，比如我们公司是做百度这种搜索服务的，就可以单独用ES,来部署一套ES集群，来存我们这个后端产生的所有数据
，将来用户在我们网站上面搜索的商品的时，从es里面去调取，在网页上面展示（？不懂感觉有点像redis）

主要作用，一方面就是为了提供数据的存储，和nosql类似，在存数据的时候也都以键值对的方式来存储。第二方面就是能实现数据的高速搜索

将来elk搜集到的所有业务服务器身上的日志之后，最终所有的日志文件都是以键值对的方式，存放在ES里面的，以后再想访问这些日志，就是再从ES里，往外调取数据

## 2.Logstash <span style="background:#affad1">L</span>
日志过滤器
比如，日志里面有状态码，我们通过elk做分析的时候，我们只想要那些成功的访问
还有一方面，根据日志的格式进行过滤
![[Pasted image 20240622151726.png]]
根据我们的需要，后面的浏览器类型我们不需要，只要前面的IP 时间等
logstash在整个部署这个elk分析的时候，logstash这个东西不是必须的。这个日志过滤功能不是必须要有的

## 3.Kibana K
在es基础上，提供一个webUI，同时这个软件还给我们提供了非常强大的<span style="background:#affad1">可视化</span>功能，在分析日志的时候，我们可以借助kibana,绘制各种图表，以图标的形式，来显示日志里面的数据。但是想绘制什么样子的图，可能需要安装相应的插件。

# 三.完整流程
![[Pasted image 20240622153352.png]]

业务规模很大的时候，可以借助<span style="background:#affad1">自动化工具</span>做统一的部署，但是，你要想让任何一个东西自动化起来，你得清楚他手动的流程。

<font color="#d99694">上面一直说是elk搜集的业务服务器上面的日志，这种说法，是不准确的，正经说，是谁做的业务的业<span style="background:#affad1">日志采集</span>？是我们在业务服务器里装的<span style="background:#affad1">beat软件</span>，这个软件搜集到业务服务器上面的日之后，再借助网络统一发送到elk那边，再把它存起来。</font>

以后公司里面，业务规模会不一样，日志量不一样，每个人的设计方式也会有所不同。在大规模的项目环境下，我们的日志文件很多，单个日志文件甚至可以达到几个G。
beat软件是go语言写的，运行效率很高的速度很快，而logstash,es,kibana，都是java写的性能相对来说较差，这样子，beat采集日志的速度很快，不停的给logstash，如果日志量很大的时候，容易造成logstash的堵塞，所有有时候中间会增加一个缓存。
![[Pasted image 20240622155120.png]]
但是一定要注意，前提是日志量很大的时候，如果就是正常的量，加上redis后期维护的成本会很大，假如后期elk接受不到日志信息了，要检查就得从头检查。

一般在设计es的时候，他本是就是一个分布式的东西，所以为了进一步增加他的性能，我们在设计es的时候，也都是以高可用的环境进行设计，也只有多个es才能发挥出es高性能的优势，logstash中传输过来的日志，也是按照es这个软件内部特定的算法分散存储到不同的es上面的。<span style="background:#affad1">但凡说某个东西是分布式的，内部一样是有副本机制的</span>，数据存进来之后，默认也是三副本的方式，单台es故障不会影响日志分析

这日志搜集过来，转到es里面存储的时候，平常我们系统上看，这是一行日志
![[Pasted image 20240622160749.png]]
转到es上以后，会按照一定的规则，被拆分为多个键值对，最终落到es里面
es里面存的每一份数据叫一个分片，说白一点，就是某个键值对的数据，分片里面有所谓的，主分片和副本分片




# 四.ELK部署
## 1.环境部署
192.168.140.10 es-master.linux.com jdk/elasticsearch/kibana/logstash
192.168.140.11 es-node01.linux.com jdk/elasticsearch
192.168.140.12 es-node02.linux.com jdk/elasticsearch
192.168.140.13 web_server.linux.com httpd/filebeat

## 2.确保SELinux关闭/时间同步

3.所有主机免密互通
ssh-keygen -t rsa
mv /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
scp -r /root/.ssh/ root@192.168.140.11:/root/
scp -r /root/.ssh/ root@192.168.140.12:/root/
scp -r /root/.ssh/ root@192.168.140.13:/root/
## 4.所有主机添加主机名解析
vim /etc/hosts
192.168.140.10	es-master.linux.com	es-master
192.168.140.11	es-node01.linux.com	es-node01
192.168.140.12	es-node02.linux.com	es-node02
192.168.140.13	web.linux.com	web
scp /etc/hosts root@192.168.140.11:/etc/hosts
scp /etc/hosts root@192.168.140.12:/etc/hosts
scp /etc/hosts root@192.168.140.13:/etc/hosts

## 5.三台ES主机安装jdk 1.15
```bash
tar xf jdk-15.0.2_linux-x64_bin.tar.gz -C /usr/local/
vim /etc/profile
    export JAVA_HOME=/usr/local/jdk-15.0.2
    export PATH=$PATH:$JAVA_HOME/bin
source /etc/profile
java -version
```

## 6.调整系统资源限制
三台es主机都要弄
```bash
vim /etc/security/limits.conf
* soft nofile 65536 
* hard nofile 65536
* soft noproc 2048
* hard noproc 4096
```
![[Pasted image 20240623110137.png]]
```bash
*           :   全部用户
nofile   ： 系统允许的最大文件描述符数量
noproc： 系统允许的最大进程数
```
vim /etc/sysctl.conf
    vm.max_map_count = 262144 
    fs.file-max = 655360
sysctl -p
![[Pasted image 20240623110740.png]]
vim /etc/security/limits.d/20-nproc.conf
![[Pasted image 20240623110804.png]]

## 7.部署es集群
### 7.1 创建用户/安装es软件
创建普通用户elk、安装es软件
useradd elk
mkdir -p /app/elk
tar xf elasticsearch-7.6.2-linux-x86_64.tar.gz -C /app/elk/
chown -R elk.elk /app/elk/

### 7.2 编辑es的配置文件
**es-master:**
```bash
su - elk
mkdir /app/elk/elasticsearch-7.6.2/data
vim /app/elk/elasticsearch-7.6.2/config/elasticsearch.yml
```
```bash title:elasticsearch.yml
# yml文件要遵从语法结构，冒号后面的空格不能删
cluster.name: es  # 集群名，三个机器要保持相同
node.name: es-master
path.data: /app/elk/elasticsearch-7.6.2/data/
path.logs: /app/elk/elasticsearch-7.6.2/logs
network.host: 192.168.140.10
http.port: 9200   # es工作端口，以后kibana对接，就是要走9200这个带端口
transport.tcp.port: 9300 # 这个要额外写，用于es三机器互相传递心跳
discovery.seed_hosts: ["192.168.140.10:9300", "192.168.140.11:9300", "192.168.140.12:9300" ]
cluster.initial_master_nodes: ["192.168.140.10:9300"]
# 这些配置，配置文件里面没有用来定义es的角色的
#根据每个机器所能做的事不同，他是有所谓的角色之分的
node.master: true         # 主节点
node.data: true
node.ingest: false
node.ml: false
cluster.remote.connect: false
http.cors.enabled: true
http.cors.allow-origin: true
```

节点类型说明:
<font color="#d99694">Master node</font>
负责集群自身的管理操作；例如创建索引、添加节点、删除节点
node.master: true

<font color="#d99694">Data node</font>
负责数据读写
建议实际部署时，使用高内存、高硬盘的服务器
node.data: true

Ingest node
预处理节点
负责数据预处理(解密、压缩、格式转换)

Client node
负责路由用户的操作请求
node.master: false
node.data: false

es-node01:
![[Pasted image 20240623114203.png]]
es-node02:
![[Pasted image 20240623114328.png]]


### 7.3 启动es集群
/app/elk/elasticsearch-7.6.2/bin/elasticsearch -d
netstat -tunlp | grep java
![[Pasted image 20240623122327.png]]
![[Pasted image 20240623122339.png]]
![[Pasted image 20240623122350.png]]
启动时候会报错，可以调大虚拟机内存

### 7.4 查看es集群状态

curl -X GET "http://192.168.140.11:9200/_cluster/health?pretty"
![[Pasted image 20240623123414.png]]
![[Pasted image 20240623123455.png]]

## 8.配置logstash
### 8.1 安装logstash
tar xf logstash-7.6.2.tar.gz -C /app/elk/
cd /app/elk/logstash-7.6.2/config/
cp logstash-sample.conf logstash.conf
### 8.2 编辑logstash配置
vim /app/elk/logstash-7.6.2/config/logstash.conf

### 8.3 启动logstash

## 9.安装kibana可视化工具
## 10.在业务服务器上部署filebeat
### 10.1 测试访问web，形成日志

### 10.2 安装filebeat
### 10.3 编辑filebeat配置

### 10.4 启动filebeat

# 五.测试ELK可正常搜集日志
## 1.在kibana webUI根据索引查看日志
## 2.创建图表，分析网站访问量























